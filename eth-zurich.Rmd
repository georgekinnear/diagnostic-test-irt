---
title: "Analysis of the ETH Zurich data; comparing 2018 to 2019"
author: "Based on work by George Kinnear"
date: "2020-06-04"
output: 
  html_document:
    toc: true
    toc_float: true
editor_options: 
  chunk_output_type: console
---

```{r load-packages, message=FALSE, include=FALSE}
library(mirt)      # For IRT analysis
library(psych)     # For factor analysis
library(tidyverse) # For data wrangling and visualisation
library(reshape)   # For reshaping nested lists
library(vroom)     # For reading in many files at once
library(broom)     # For tidying model output
library(fs)        # For file system operations
library(gt)        # For formatting tables
library(knitr)     # For markdown tables
library(ggrepel)   # For labelling points without overlap
library(skimr)     # For data frame level summary
library(ggridges)  # For ridge plots
library(plotly)    # For interactive plots
```

## Data

Load the data from the two years and bind them to create a single data frame:

```{r load-all-data, message=FALSE}
# load data
eth_2018 <- read_csv("data/2018-q32/all-2018.csv")
eth_2019 <- read_csv("data/2019-q32/all-2019.csv")

# add year as the identifier column to each data frame
eth_2018 <- eth_2018 %>% 
  mutate(year = 2018)
eth_2019 <- eth_2019 %>% 
  mutate(year = 2019)

# bind the two data frames together
eth <- bind_rows(eth_2019, eth_2018) %>%
  relocate(year)
```

Skim an overview of the data:

```{r skim-all-data}
skim(eth) %>% kable()
```

## Fitting 2 parameter logistic MIRT model

We can fit a Multidimensional Item Response Theory (mirt) model. From the function definition:

```
mirt fits a maximum likelihood (or maximum a posteriori) factor analysis model to any mixture of dichotomous and polytomous data under the item response theory paradigm using either Cai's (2010) Metropolis-Hastings Robbins-Monro (MHRM) algorithm.
```

The process is to first fit the model, and save the result as a model object that we can then parse to get tabular or visual displays of the model that we might want. When fitting the model, we have the option to specify a few arguments, which then get interpreted as parameters to be passed to the model.

```{r fit-mirt}
fit_2pl <- mirt(
  data = eth[2:33],  # all but the year column
  model = 1,         # number of factors to extract
  itemtype = "2PL",  # 2 parameter logistic model
  SE = TRUE          # estimate standard errors
  )
```

We then compute factor score estimates and augment the existing data frame with these estimates, to keep everything in one place. To do the estimation, we use the `fscores()` function from the mirt package which takes in a computed model object and computes factor score estimates according to the method specified. We will use the EAP method for factor score estimation, which is the "expected a-posteriori" method, the default. We specify it explicitl below, but the results would have been the same if we omitted specifying the method arhument since it's the default method the function uses.

```{r augment-with-f1}
eth <- eth %>%
  mutate(F1 = fscores(fit_2pl, method = "EAP"))
```

We can also calculate the model coefficient estimates using a generic function `coef()` which is used to extract model coefficients from objects returned by modeling functions. We will set the `IRTpars` argument to `TRUE`, which means slope intercept parameters will be converted into traditional IRT parameters.

```{r extract-coefs}
coefs_2pl <- coef(fit_2pl, IRTpars = TRUE)
```

The resulting object `coefs` is a list, with one element for each question, and an additional `GroupPars` element that we won't be using. The output is a bit long, so we're only showing a few of the elements here:

```{r peek-coefs}
coefs_2pl[1:3]
# coefs_2pl[35:37]
```

Let's take a closer look at the first element:

```{r coef-1}
coefs_2pl[1]
```

In this output:

* `a` is discrimination
* `b` is difficulty
* endpoints of the 95% confidence intervals are also shown

To make this output a little more user friendly, we should tidy it such that we have a row per question. We'll do this in two steps. First, write a function that tidies the output for one question, i.e. one list element. Then, map this function over the list of all questions, resulting in a data frame.

```{r f-tidy-mirt-coefs}
tidy_mirt_coefs <- function(x){
  x %>%
    # melt the list element
    melt() %>%
    # convert to a tibble
    as_tibble() %>%
    # convert factors to characters
    mutate(across(where(is.factor), as.character)) %>%
    # only focus on rows where X2 is a or b (discrimination or difficulty)
    filter(X2 %in% c("a", "b")) %>%
    # in X1, relabel par (parameter) as est (estimate)
    mutate(X1 = if_else(X1 == "par", "est", X1)) %>%
    # unite columns X2 and X1 into a new column called var separated by _
    unite(X2, X1, col = "var", sep = "_") %>%
    # turn into a wider data frame
    pivot_wider(names_from = var, values_from = value)
}
```

Let's see what this does to a single element in `coefs`:

```{r apply-once-tidy-mirt-coefs}
tidy_mirt_coefs(coefs_2pl[1])
```

And now let's map it over all 32 elements of coefs:

```{r map-tidy-mirt-coefs}
tidy_2pl <- map_dfr(coefs_2pl[1:32], tidy_mirt_coefs, .id = "Question")
```

A quick peek at the result:

```{r peek-tidy-output}
tidy_2pl
```

And a nicely formatted table of the result:

```{r tabulate-tidy-output, eval=FALSE}
gt(tidy_2pl) %>%
  fmt_number(columns = contains("_"), decimals = 3) %>%
  data_color(
    columns = contains("a_"),
    colors = scales::col_numeric(palette = c("Greens"), domain = NULL)
  ) %>%
  data_color(
    columns = contains("b_"),
    colors = scales::col_numeric(palette = c("Blues"), domain = NULL)
  ) %>%
  tab_spanner(label = "Discrimination", columns = contains("a_")) %>%
  tab_spanner(label = "Difficulty", columns = contains("b_")) %>%
  cols_label(
    a_est = "Est.",
    b_est = "Est.",
    a_CI_2.5 = "2.5%",
    b_CI_2.5 = "2.5%",
    a_CI_97.5 = "97.5%",
    b_CI_97.5 = "97.5%"
  )
```

### Comparing years and classes

Do students from different programmes of study have different distributions of ability?

```{r class-data, message=FALSE}
# produce list of all the relevant file names
# (match only the courses beginning 401, i.e. exclude "all.csv")
files <- dir_ls("data/", recurse = TRUE, regexp = "401.*.csv")
files <- files[!str_detect(files, "q36")]

# read all files and add a column called file_path to identify them
eth_entry_test <- vroom(files, id = "file_path")

# parse file_path column into year and class
eth_entry_test <- eth_entry_test %>%
  mutate(
    file_path = str_remove(file_path, "data/"),
    file_path = str_remove(file_path, "-q32"),
    file_path = str_remove(file_path, ".csv"),
    ) %>%
  separate(file_path, c("year", "class"), sep = "/") %>%
  mutate(class = str_remove(class, "-2019"))

# fit IRT model
fit_2pl <- mirt(
  eth_entry_test[3:34],  # all but the year and class columns
  model = 1,             # number of factors to extract
  itemtype = "2PL",      # 2 parameter logistic model
  SE = TRUE              # estimate standard errors
  )

# augment data with factor scores from model fit
eth_entry_test <- eth_entry_test %>%
  mutate(F1 = fscores(fit_2pl, method = "EAP"))
```

### Differences between years

Compare the distribution of abilities in the two years.

```{r viz-years}
ggplot(eth_entry_test, aes(F1, fill = as.factor(year), colour = as.factor(year))) +
  geom_density(alpha=0.5) + 
  scale_x_continuous(limits = c(-3.5,3.5)) +
  labs(title = "Density plot", 
       subtitle = "Ability grouped by year of taking the test", 
       x = "Ability", y = "Density",
       fill = "Year", colour = "Year") +
  theme_minimal()
```

There does not seem to be a big difference between the two year groups, so we combine them in the following analysis.

### Differences between classes

Compare the distribution of abilities in the various classes.

```{r viz-classes}
ggplot(eth_entry_test, aes(x = F1, y = class, colour = class, fill = class)) +
  geom_density_ridges(alpha = 0.5) + 
  scale_x_continuous(limits = c(-3.5,3.5)) +
  guides(fill = FALSE, colour = FALSE) +
  labs(title = "Density plot", 
       subtitle = "Ability grouped by class of taking the test", 
       x = "Ability", y = "Class") +
  theme_minimal()
```

## Information curves

### Test information curves

```{r}
eth_2019 <- eth_2019 %>% relocate(year)
eth_2018 <- eth_2018 %>% relocate(year)

fit_2pl_2019 <- mirt(
  data = eth_2019[2:33],  # all but the year column
  model = 1,         # number of factors to extract
  itemtype = "2PL",  # 2 parameter logistic model
  SE = TRUE          # estimate standard errors
  )

fit_2pl_2018 <- mirt(
  data = eth_2018[2:33],  # all but the year column
  model = 1,         # number of factors to extract
  itemtype = "2PL",  # 2 parameter logistic model
  SE = TRUE          # estimate standard errors
  )
```

```{r}
plot(fit_2pl_2019, type = "info", main = "Test information, 2019")
plot(fit_2pl_2018, type = "info", main = "Test information, 2019")
```

### Item information curves

## Response curves

### Test response curves

### Item response curves

We can get individual item surface and information plots using the `itemplot()` function from the **mirt** package, e.g.

```{r}
mirt::itemplot(fit_2pl_2019, item = 1, 
               main = "2019 2PL\nTrace lines for item 1")
```

We can also get the plots for all trace lines, one facet per plot.

```{r}
plot(fit_2pl_2019, type = "trace", auto.key = FALSE)
```

Or all of them overlaid in one plot.

```{r}
plot(fit_2pl_2019, type = "trace", facet_items=FALSE)
```

An alternative approach is using ggplot2 and plotly to add interactivity to make it easier to identify items.

```{r warning=FALSE}
# store the object
plt <- plot(fit_2pl_2019, type = "trace", facet_items = FALSE)
# the data we need is in panel.args
plt_data <- tibble(
  x          = plt$panel.args[[1]]$x,
  y          = plt$panel.args[[1]]$y,
  subscripts = plt$panel.args[[1]]$subscripts,
  item       = rep(colnames(eth_2019[2:33]), each = 200)
) %>%
  mutate(
    item_no = str_remove(item, "A") %>% as.numeric(),
    item    = fct_reorder(item, item_no)
    )

head(plt_data)

p_2019 <- ggplot(plt_data, aes(x, y, 
                          colour = item, 
                          text = item)) + 
  geom_line() + 
  labs(
    title = "2019 2PL - Trace lines",
    #x = expression(theta),
    x = "theta",
    #y = expression(P(theta)),
    y = "P(theta)",
    colour = "Item"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

ggplotly(p_2019, tooltip = "text")
```

```{r}
# store the object
plt <- plot(fit_2pl_2018, type = "trace", facet_items = FALSE)
# the data we need is in panel.args
plt_data <- tibble(
  x          = plt$panel.args[[1]]$x,
  y          = plt$panel.args[[1]]$y,
  subscripts = plt$panel.args[[1]]$subscripts,
  item       = rep(colnames(eth_2018[2:33]), each = 200)
) %>%
  mutate(
    item_no = str_remove(item, "A") %>% as.numeric(),
    item    = fct_reorder(item, item_no)
    )

head(plt_data)

p_2018 <- ggplot(plt_data, aes(x, y, 
                          colour = item, 
                          text = item)) + 
  geom_line() + 
  labs(
    title = "2018 2PL - Trace lines",
    #x = expression(theta),
    x = "theta",
    #y = expression(P(theta)),
    y = "P(theta)",
    colour = "Item"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

ggplotly(p_2018, tooltip = "text")
```


```{r}
knitr::knit_exit()
```






library(RColorBrewer)
library(ggpubr)
pal36 <- c(brewer.pal(8, "Purples")[3:8], brewer.pal(8, "Greens")[3:8], brewer.pal(8, "Oranges")[3:8], brewer.pal(8, "Blues")[3:8], brewer.pal(8, "Reds")[3:8], brewer.pal(8, "Greys")[3:8])

source("myggplot-mirt.R")

myggplot.mirt(fit_2pl_2019,  col = pal36)
```

```{r eval=FALSE}
# this didn't work
par(mfrow = c(8,4))

for(i in 1:32){
  itemplot(fit_2pl_2019, type = "info", item = i)
}
```

```{r}
knitr::knit_exit()
```


## Factor analysis

```{r fa}
fa.parallel(eth[2:33], fa = "fa")
```

### 1 Factor

```{r fa1}
fitfact <- factanal(eth[2:33], 1, rotation = "varimax")
print(fitfact, digits = 2, cutoff = 0.3, sort = TRUE)

load <- tidy(fitfact)

ggplot(load, aes(x = fl1, y = 0)) + 
  geom_point() + 
  geom_label_repel(aes(label = paste0("A", rownames(load))), show.legend = FALSE) +
  labs(x = "Factor 1", y = NULL,
       title = "Standardised Loadings", 
       subtitle = "Based upon correlation matrix") +
  theme_minimal()
```

### 2 Factors

```{r fa2}
fitfact <- factanal(eth[2:33], 2, rotation = "varimax")
print(fitfact, digits = 2, cutoff = 0.3, sort = TRUE)

load <- tidy(fitfact)

ggplot(load, aes(x = fl1, y = fl2)) + 
  geom_point() + 
  geom_label_repel(aes(label = paste0("A", rownames(load))), show.legend = FALSE) +
  labs(x = "Factor 1", y = "Factor 2",
       title = "Standardised Loadings", 
       subtitle = "Based upon correlation matrix") +
  theme_minimal()
```

### 9 Factors (showing only first 2)

#```{r fa9}
#fitfact <- factanal(eth[2:37], 9, rotation = "varimax")
#print(fitfact, digits = 2, cutoff = 0.3, sort = TRUE)

#load <- tidy(fitfact)

#ggplot(load, aes(x = fl1, y = fl2)) + 
#  geom_point() + 
#  geom_label_repel(aes(label = paste0("A", rownames(load))), #show.legend = FALSE) +
#  labs(x = "Factor 1", y = "Factor 2",
#       title = "Standardised Loadings", 
#       subtitle = "Based upon correlation matrix") +
#  theme_minimal()
#```

## Packages

In this analysis we used the following packages. You can learn more about each one by clicking on the links below.

- [**mirt**](https://cran.r-project.org/web/packages/mirt/mirt.pdf): For IRT analysis
- [**psych**](https://personality-project.org/r/psych/): For factor analysis
- [**tidyverse**](https://tidyverse.org/): For data wrangling and visualisation
- [**reshape**](http://had.co.nz/reshape/): For reshaping nested lists
- [**vroom**](https://vroom.r-lib.org/): For reading in many files at once
- [**broom**](https://broom.tidymodels.org/): For tidying model output
- [**fs**](https://fs.r-lib.org/): For file system operations
- [**gt**](https://gt.rstudio.com/): For formatting tables
- [**knitr**](https://yihui.org/knitr/): For markdown tables
- [**ggrepel**](https://ggrepel.slowkow.com/): For labelling points without overlap
- [**skimr**](https://docs.ropensci.org/skimr/): For data frame level summary
- [**ggridges**](https://wilkelab.org/ggridges/): For ridge plots


